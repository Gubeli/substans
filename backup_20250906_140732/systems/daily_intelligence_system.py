#!/usr/bin/env python3
"""
Daily Intelligence System - SystÃ¨me de Veille Quotidienne AutomatisÃ©e
Chaque agent expert exÃ©cute quotidiennement une session de veille dans son domaine
GÃ©nÃ¨re des rapports d'enrichissement intÃ©grÃ©s Ã  la base de connaissances
"""

import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any
import hashlib
import os

class DailyIntelligenceSystem:
    def __init__(self):
        self.name = "Daily Intelligence System"
        self.version = "1.0"
        self.intelligence_reports = []
        self.knowledge_enrichment_log = []
        
        # Configuration des agents experts et leurs domaines de veille
        self.expert_agents = {
            "ESS": {
                "name": "Expert Semi-conducteurs & Substrats",
                "domains": ["semi-conducteurs", "HPC", "supercalcul", "BullSequana", "BXI"],
                "sources": [
                    "IEEE Spectrum", "EE Times", "AnandTech", "HPCwire", 
                    "Top500.org", "Eviden.com", "Nvidia.com", "Intel.com"
                ],
                "keywords": [
                    "BullSequana", "exascale", "HPC", "supercalculateur", "BXI",
                    "interconnect", "Nvidia H100", "Intel Ponte Vecchio", "AMD MI300"
                ],
                "expertise_level": "senior_engineer_15_years"
            },
            
            "EDDI": {
                "name": "Expert Digital, Data, IA",
                "domains": ["intelligence artificielle", "data", "transformation digitale"],
                "sources": [
                    "MIT Technology Review", "VentureBeat AI", "TechCrunch", "Wired",
                    "OpenAI.com", "Google AI", "Microsoft AI", "Anthropic.com"
                ],
                "keywords": [
                    "GPT", "LLM", "IA gÃ©nÃ©rative", "machine learning", "MLOps",
                    "DataOps", "transformation digitale", "cloud native", "edge computing"
                ],
                "expertise_level": "chief_digital_officer"
            },
            
            "EIA": {
                "name": "Expert Intelligence Artificielle",
                "domains": ["IA", "machine learning", "deep learning", "AGI"],
                "sources": [
                    "ArXiv.org", "Papers With Code", "Towards Data Science", "AI Research",
                    "OpenAI Research", "DeepMind", "Anthropic Research", "Hugging Face"
                ],
                "keywords": [
                    "transformer", "attention", "RLHF", "fine-tuning", "RAG",
                    "multimodal", "AGI", "alignment", "safety", "reasoning"
                ],
                "expertise_level": "ai_research_scientist"
            },
            
            "EC": {
                "name": "Expert Cloud",
                "domains": ["cloud computing", "infrastructure", "DevOps"],
                "sources": [
                    "AWS Blog", "Google Cloud Blog", "Azure Blog", "CNCF",
                    "Kubernetes.io", "Docker.com", "RedHat", "VMware"
                ],
                "keywords": [
                    "kubernetes", "serverless", "microservices", "containers",
                    "multi-cloud", "edge computing", "DevOps", "GitOps", "observability"
                ],
                "expertise_level": "cloud_architect_senior"
            },
            
            "EDATA": {
                "name": "Expert Data",
                "domains": ["data engineering", "analytics", "big data"],
                "sources": [
                    "Databricks Blog", "Snowflake Blog", "Apache Foundation", "Confluent",
                    "dbt Labs", "Fivetran", "Looker", "Tableau"
                ],
                "keywords": [
                    "data lakehouse", "data mesh", "real-time analytics", "streaming",
                    "dbt", "Apache Spark", "Kafka", "data governance", "data quality"
                ],
                "expertise_level": "chief_data_officer"
            },
            
            "ELRD": {
                "name": "Expert LÃ©gislations & RÃ©glementations Digitales",
                "domains": ["rÃ©glementation", "compliance", "RGPD", "DMA", "DSA"],
                "sources": [
                    "EUR-Lex", "CNIL", "Commission EuropÃ©enne", "FTC", "DOJ",
                    "Privacy International", "IAPP", "TechPolicy"
                ],
                "keywords": [
                    "RGPD", "DMA", "DSA", "AI Act", "GDPR", "privacy",
                    "data protection", "antitrust", "competition", "sovereignty"
                ],
                "expertise_level": "regulatory_affairs_director"
            },
            
            "ESTRAT": {
                "name": "Expert StratÃ©gie",
                "domains": ["stratÃ©gie", "business", "consulting", "M&A"],
                "sources": [
                    "McKinsey Insights", "BCG Insights", "Bain Insights", "Deloitte",
                    "Harvard Business Review", "MIT Sloan", "Strategy+Business"
                ],
                "keywords": [
                    "digital transformation", "business model", "competitive advantage",
                    "innovation strategy", "M&A", "corporate strategy", "disruption"
                ],
                "expertise_level": "partner_strategy_consulting"
            },
            
            "ECYBER": {
                "name": "Expert CybersÃ©curitÃ©",
                "domains": ["cybersÃ©curitÃ©", "sÃ©curitÃ©", "cyber threats"],
                "sources": [
                    "CISA", "NIST", "ANSSI", "Krebs on Security", "Dark Reading",
                    "Security Week", "Threatpost", "SANS"
                ],
                "keywords": [
                    "zero trust", "ransomware", "APT", "threat intelligence",
                    "SIEM", "SOC", "incident response", "vulnerability", "penetration testing"
                ],
                "expertise_level": "chief_security_officer"
            }
        }

    def execute_daily_intelligence_cycle(self) -> Dict[str, Any]:
        """
        ExÃ©cute le cycle quotidien de veille pour tous les agents experts
        """
        print(f"ðŸŒ… DÃ©marrage du cycle de veille quotidienne - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        
        daily_reports = {}
        enrichment_summary = {
            "date": datetime.now().strftime('%Y-%m-%d'),
            "total_agents": len(self.expert_agents),
            "reports_generated": 0,
            "knowledge_items_added": 0,
            "intelligence_score": 0.0
        }
        
        for agent_id, agent_config in self.expert_agents.items():
            print(f"\nðŸ” {agent_config['name']} - DÃ©but de la veille...")
            
            # ExÃ©cution de la veille pour cet agent
            agent_report = self._execute_agent_intelligence(agent_id, agent_config)
            daily_reports[agent_id] = agent_report
            
            # IntÃ©gration Ã  la base de connaissances
            knowledge_integration = self._integrate_to_knowledge_base(agent_id, agent_report)
            
            enrichment_summary["reports_generated"] += 1
            enrichment_summary["knowledge_items_added"] += knowledge_integration["items_added"]
            
            print(f"âœ… {agent_config['name']} - Veille terminÃ©e: {agent_report['findings_count']} dÃ©couvertes")
        
        # Calcul du score d'intelligence global
        enrichment_summary["intelligence_score"] = self._calculate_intelligence_score(daily_reports)
        
        # Sauvegarde du cycle quotidien
        cycle_result = {
            "cycle_id": self._generate_cycle_id(),
            "date": datetime.now().isoformat(),
            "summary": enrichment_summary,
            "agent_reports": daily_reports,
            "knowledge_enrichment": self.knowledge_enrichment_log[-len(self.expert_agents):]
        }
        
        self.intelligence_reports.append(cycle_result)
        
        print(f"\nðŸŽ¯ Cycle quotidien terminÃ©: {enrichment_summary['reports_generated']} rapports, {enrichment_summary['knowledge_items_added']} enrichissements")
        
        return cycle_result

    def _execute_agent_intelligence(self, agent_id: str, agent_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        ExÃ©cute la session de veille pour un agent spÃ©cifique
        """
        # Simulation de la veille (en production, ceci ferait de vraies recherches)
        intelligence_findings = self._simulate_intelligence_gathering(agent_id, agent_config)
        
        # Analyse et synthÃ¨se des dÃ©couvertes
        analysis = self._analyze_findings(agent_id, intelligence_findings, agent_config)
        
        # GÃ©nÃ©ration du rapport quotidien
        daily_report = {
            "agent_id": agent_id,
            "agent_name": agent_config["name"],
            "date": datetime.now().strftime('%Y-%m-%d'),
            "veille_duration": "2 heures",
            "sources_consulted": len(agent_config["sources"]),
            "keywords_monitored": len(agent_config["keywords"]),
            "findings_count": len(intelligence_findings),
            "intelligence_findings": intelligence_findings,
            "analysis": analysis,
            "learning_summary": self._generate_learning_summary(agent_id, intelligence_findings),
            "performance_enhancement": self._assess_performance_enhancement(agent_id, intelligence_findings),
            "next_focus_areas": self._identify_next_focus_areas(agent_id, intelligence_findings)
        }
        
        return daily_report

    def _simulate_intelligence_gathering(self, agent_id: str, agent_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Simule la collecte d'intelligence (en production: vraies recherches web/API)
        """
        # Simulation de dÃ©couvertes selon le domaine de l'agent
        simulated_findings = {
            "ESS": [
                {
                    "title": "Nvidia annonce la nouvelle architecture Blackwell pour l'IA",
                    "source": "Nvidia Blog",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.95,
                    "summary": "Nouvelle architecture GPU Blackwell avec performance 4x supÃ©rieure pour l'IA gÃ©nÃ©rative",
                    "impact": "Concurrence directe avec BullSequana XH3000",
                    "keywords": ["Nvidia", "Blackwell", "GPU", "IA", "performance"]
                },
                {
                    "title": "Intel dÃ©voile sa roadmap HPC 2025-2027",
                    "source": "Intel Newsroom",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.88,
                    "summary": "Intel prÃ©sente sa stratÃ©gie HPC avec focus sur l'efficacitÃ© Ã©nergÃ©tique",
                    "impact": "Positionnement concurrentiel Ã  analyser vs BullSequana",
                    "keywords": ["Intel", "HPC", "roadmap", "efficacitÃ© Ã©nergÃ©tique"]
                },
                {
                    "title": "JUPITER atteint 1 exaflop - Premier supercalculateur exascale europÃ©en",
                    "source": "HPCwire",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.92,
                    "summary": "Le supercalculateur JUPITER basÃ© sur BullSequana XH3000 atteint l'exascale",
                    "impact": "Validation technologique majeure pour Bull/Eviden",
                    "keywords": ["JUPITER", "exascale", "BullSequana", "Europe", "souverainetÃ©"]
                }
            ],
            
            "EDDI": [
                {
                    "title": "OpenAI lance GPT-5 avec capacitÃ©s de raisonnement avancÃ©es",
                    "source": "OpenAI Blog",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.96,
                    "summary": "GPT-5 introduit des capacitÃ©s de raisonnement multi-Ã©tapes et planification",
                    "impact": "RÃ©volution pour les applications IA d'entreprise",
                    "keywords": ["GPT-5", "raisonnement", "IA gÃ©nÃ©rative", "entreprise"]
                },
                {
                    "title": "Microsoft annonce Copilot Enterprise avec RAG avancÃ©",
                    "source": "Microsoft Blog",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.89,
                    "summary": "Nouvelle version de Copilot intÃ©grant RAG pour donnÃ©es d'entreprise",
                    "impact": "AccÃ©lÃ©ration de l'adoption IA en entreprise",
                    "keywords": ["Microsoft", "Copilot", "RAG", "entreprise", "productivitÃ©"]
                }
            ],
            
            "ELRD": [
                {
                    "title": "L'UE finalise l'AI Act - EntrÃ©e en vigueur fÃ©vrier 2025",
                    "source": "Commission EuropÃ©enne",
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "relevance": 0.94,
                    "summary": "L'AI Act europÃ©en entre en vigueur avec obligations pour les systÃ¨mes IA Ã  haut risque",
                    "impact": "Impact majeur sur le dÃ©veloppement et dÃ©ploiement d'IA",
                    "keywords": ["AI Act", "UE", "rÃ©glementation", "IA", "compliance"]
                }
            ]
        }
        
        return simulated_findings.get(agent_id, [
            {
                "title": f"DÃ©veloppement dans le domaine de {agent_config['name']}",
                "source": "Source spÃ©cialisÃ©e",
                "date": datetime.now().strftime('%Y-%m-%d'),
                "relevance": 0.75,
                "summary": f"Nouvelle Ã©volution dans {agent_config['domains'][0]}",
                "impact": "Ã€ analyser selon expertise sectorielle",
                "keywords": agent_config['keywords'][:3]
            }
        ])

    def _analyze_findings(self, agent_id: str, findings: List[Dict], agent_config: Dict) -> Dict[str, Any]:
        """
        Analyse les dÃ©couvertes avec l'expertise de l'agent
        """
        analysis = {
            "key_trends": [],
            "competitive_intelligence": [],
            "technology_shifts": [],
            "regulatory_changes": [],
            "market_opportunities": [],
            "strategic_implications": [],
            "risk_assessment": []
        }
        
        for finding in findings:
            relevance = finding.get("relevance", 0.5)
            
            if relevance > 0.9:
                analysis["key_trends"].append({
                    "trend": finding["title"],
                    "impact": finding["impact"],
                    "confidence": "high"
                })
            
            if any(keyword in finding["title"].lower() for keyword in ["concurrent", "competitor", "vs", "against"]):
                analysis["competitive_intelligence"].append({
                    "intelligence": finding["summary"],
                    "competitive_impact": finding["impact"]
                })
            
            if any(keyword in finding["title"].lower() for keyword in ["nouveau", "innovation", "breakthrough", "rÃ©volution"]):
                analysis["technology_shifts"].append({
                    "technology": finding["title"],
                    "disruption_potential": "high" if relevance > 0.9 else "medium"
                })
        
        # Implications stratÃ©giques spÃ©cifiques Ã  l'agent
        if agent_id == "ESS":
            analysis["strategic_implications"] = [
                "Renforcement nÃ©cessaire de la roadmap BullSequana face Ã  Nvidia Blackwell",
                "OpportunitÃ© de valoriser les succÃ¨s JUPITER pour le positionnement europÃ©en",
                "Surveillance accrue des dÃ©veloppements Intel HPC"
            ]
        elif agent_id == "EDDI":
            analysis["strategic_implications"] = [
                "IntÃ©gration des capacitÃ©s GPT-5 dans les solutions Bull",
                "DÃ©veloppement d'une stratÃ©gie Copilot Enterprise concurrente",
                "Positionnement sur l'IA d'entreprise avec souverainetÃ© europÃ©enne"
            ]
        
        return analysis

    def _generate_learning_summary(self, agent_id: str, findings: List[Dict]) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re un rÃ©sumÃ© des apprentissages pour l'agent
        """
        learning_summary = {
            "new_knowledge_areas": [],
            "expertise_enhancement": [],
            "capability_expansion": [],
            "performance_improvement_potential": 0.0
        }
        
        # Analyse des nouveaux domaines de connaissance
        for finding in findings:
            if finding.get("relevance", 0) > 0.8:
                learning_summary["new_knowledge_areas"].append({
                    "area": finding["title"],
                    "knowledge_depth": "high" if finding.get("relevance", 0) > 0.9 else "medium",
                    "application_potential": finding["impact"]
                })
        
        # Ã‰valuation de l'amÃ©lioration des performances
        high_relevance_count = sum(1 for f in findings if f.get("relevance", 0) > 0.8)
        learning_summary["performance_improvement_potential"] = min(1.0, high_relevance_count * 0.1)
        
        return learning_summary

    def _assess_performance_enhancement(self, agent_id: str, findings: List[Dict]) -> Dict[str, Any]:
        """
        Ã‰value l'amÃ©lioration des performances de l'agent
        """
        enhancement = {
            "knowledge_base_expansion": len(findings),
            "expertise_deepening": sum(f.get("relevance", 0) for f in findings) / len(findings) if findings else 0,
            "competitive_awareness": len([f for f in findings if "concurren" in f.get("impact", "").lower()]),
            "innovation_tracking": len([f for f in findings if f.get("relevance", 0) > 0.9]),
            "overall_enhancement_score": 0.0
        }
        
        # Calcul du score global d'amÃ©lioration
        base_score = enhancement["expertise_deepening"]
        innovation_bonus = enhancement["innovation_tracking"] * 0.1
        competitive_bonus = enhancement["competitive_awareness"] * 0.05
        
        enhancement["overall_enhancement_score"] = min(1.0, base_score + innovation_bonus + competitive_bonus)
        
        return enhancement

    def _identify_next_focus_areas(self, agent_id: str, findings: List[Dict]) -> List[str]:
        """
        Identifie les prochaines zones de focus pour l'agent
        """
        focus_areas = []
        
        # Analyse des gaps et opportunitÃ©s
        high_impact_findings = [f for f in findings if f.get("relevance", 0) > 0.85]
        
        for finding in high_impact_findings:
            if "opportunitÃ©" in finding.get("impact", "").lower():
                focus_areas.append(f"Approfondir: {finding['title']}")
            elif "concurrence" in finding.get("impact", "").lower():
                focus_areas.append(f"Surveiller: {finding['title']}")
        
        # Focus spÃ©cifiques par agent
        agent_specific_focus = {
            "ESS": ["Ã‰volution architectures GPU", "Roadmaps concurrents HPC", "Technologies interconnect"],
            "EDDI": ["IA gÃ©nÃ©rative entreprise", "Plateformes no-code/low-code", "Edge AI"],
            "ELRD": ["Ã‰volutions rÃ©glementaires IA", "Compliance multi-juridictionnelle", "Privacy tech"]
        }
        
        focus_areas.extend(agent_specific_focus.get(agent_id, ["Veille sectorielle continue"]))
        
        return focus_areas[:5]  # Limiter Ã  5 focus areas

    def _integrate_to_knowledge_base(self, agent_id: str, agent_report: Dict[str, Any]) -> Dict[str, Any]:
        """
        IntÃ¨gre le rapport de veille Ã  la base de connaissances substans.ai
        """
        integration_result = {
            "agent_id": agent_id,
            "integration_date": datetime.now().isoformat(),
            "items_added": 0,
            "knowledge_categories": [],
            "integration_success": True
        }
        
        # Simulation de l'intÃ©gration (en production: vraie base de donnÃ©es)
        findings = agent_report.get("intelligence_findings", [])
        
        for finding in findings:
            if finding.get("relevance", 0) > 0.7:  # Seuil de qualitÃ©
                knowledge_item = {
                    "id": self._generate_knowledge_id(agent_id, finding),
                    "agent_source": agent_id,
                    "title": finding["title"],
                    "content": finding["summary"],
                    "category": self._categorize_knowledge(finding),
                    "relevance_score": finding.get("relevance", 0),
                    "date_added": datetime.now().isoformat(),
                    "keywords": finding.get("keywords", []),
                    "impact_assessment": finding.get("impact", "")
                }
                
                integration_result["items_added"] += 1
                category = knowledge_item["category"]
                if category not in integration_result["knowledge_categories"]:
                    integration_result["knowledge_categories"].append(category)
        
        # Log de l'enrichissement
        enrichment_log = {
            "timestamp": datetime.now().isoformat(),
            "agent_id": agent_id,
            "items_integrated": integration_result["items_added"],
            "categories": integration_result["knowledge_categories"],
            "quality_score": sum(f.get("relevance", 0) for f in findings) / len(findings) if findings else 0
        }
        
        self.knowledge_enrichment_log.append(enrichment_log)
        
        return integration_result

    def _categorize_knowledge(self, finding: Dict[str, Any]) -> str:
        """
        CatÃ©gorise automatiquement les connaissances
        """
        title_lower = finding["title"].lower()
        
        if any(word in title_lower for word in ["concurrent", "competitor", "vs", "market share"]):
            return "competitive_intelligence"
        elif any(word in title_lower for word in ["innovation", "breakthrough", "nouveau", "rÃ©volution"]):
            return "technology_innovation"
        elif any(word in title_lower for word in ["rÃ©glementation", "loi", "compliance", "rÃ©gulation"]):
            return "regulatory_updates"
        elif any(word in title_lower for word in ["marchÃ©", "market", "industrie", "secteur"]):
            return "market_intelligence"
        elif any(word in title_lower for word in ["stratÃ©gie", "strategy", "business model"]):
            return "strategic_intelligence"
        else:
            return "general_intelligence"

    def _calculate_intelligence_score(self, daily_reports: Dict[str, Any]) -> float:
        """
        Calcule le score d'intelligence global du cycle quotidien
        """
        total_findings = sum(report.get("findings_count", 0) for report in daily_reports.values())
        total_relevance = sum(
            sum(f.get("relevance", 0) for f in report.get("intelligence_findings", []))
            for report in daily_reports.values()
        )
        
        if total_findings == 0:
            return 0.0
        
        avg_relevance = total_relevance / total_findings
        coverage_score = len(daily_reports) / len(self.expert_agents)
        
        intelligence_score = (avg_relevance * 0.7 + coverage_score * 0.3)
        
        return min(1.0, intelligence_score)

    def _generate_cycle_id(self) -> str:
        """GÃ©nÃ¨re un ID unique pour le cycle quotidien"""
        date_str = datetime.now().strftime('%Y%m%d')
        hash_input = f"{date_str}_{len(self.intelligence_reports)}"
        return f"CYCLE_{date_str}_{hashlib.md5(hash_input.encode()).hexdigest()[:8]}"

    def _generate_knowledge_id(self, agent_id: str, finding: Dict[str, Any]) -> str:
        """GÃ©nÃ¨re un ID unique pour un Ã©lÃ©ment de connaissance"""
        hash_input = f"{agent_id}_{finding['title']}_{finding.get('date', '')}"
        return f"KB_{hashlib.md5(hash_input.encode()).hexdigest()[:12]}"

    def generate_daily_intelligence_report(self) -> str:
        """
        GÃ©nÃ¨re le rapport quotidien consolidÃ© de veille
        """
        if not self.intelligence_reports:
            return "Aucun cycle de veille exÃ©cutÃ© aujourd'hui."
        
        latest_cycle = self.intelligence_reports[-1]
        summary = latest_cycle["summary"]
        
        report = f"""# ðŸ“Š RAPPORT QUOTIDIEN DE VEILLE INTELLIGENCE - {summary['date']}

## ðŸŽ¯ RÃ‰SUMÃ‰ EXÃ‰CUTIF
- **Agents mobilisÃ©s** : {summary['total_agents']} experts
- **Rapports gÃ©nÃ©rÃ©s** : {summary['reports_generated']}
- **Enrichissements KB** : {summary['knowledge_items_added']} nouveaux Ã©lÃ©ments
- **Score d'intelligence** : {summary['intelligence_score']:.2f}/1.0

## ðŸ“‹ DÃ‰COUVERTES MAJEURES PAR EXPERT

"""
        
        for agent_id, report_data in latest_cycle["agent_reports"].items():
            agent_name = report_data["agent_name"]
            findings_count = report_data["findings_count"]
            
            report += f"### {agent_name}\n"
            report += f"- **DÃ©couvertes** : {findings_count}\n"
            report += f"- **Sources consultÃ©es** : {report_data['sources_consulted']}\n"
            
            # Top dÃ©couvertes
            top_findings = sorted(
                report_data.get("intelligence_findings", []),
                key=lambda x: x.get("relevance", 0),
                reverse=True
            )[:2]
            
            for finding in top_findings:
                report += f"  - ðŸ” **{finding['title']}** (Relevance: {finding.get('relevance', 0):.2f})\n"
                report += f"    - {finding['summary']}\n"
                report += f"    - Impact: {finding['impact']}\n"
            
            report += "\n"
        
        report += f"""## ðŸ§  ENRICHISSEMENT DE LA BASE DE CONNAISSANCES

"""
        
        for enrichment in latest_cycle["knowledge_enrichment"]:
            agent_id = enrichment["agent_id"]
            items = enrichment["items_integrated"]
            quality = enrichment["quality_score"]
            
            report += f"- **{agent_id}** : {items} Ã©lÃ©ments ajoutÃ©s (QualitÃ©: {quality:.2f})\n"
        
        report += f"""
## ðŸ“ˆ MÃ‰TRIQUES DE PERFORMANCE
- **Couverture sectorielle** : {len(latest_cycle['agent_reports'])}/{len(self.expert_agents)} domaines
- **QualitÃ© moyenne** : {summary['intelligence_score']:.2f}/1.0
- **Enrichissement KB** : +{summary['knowledge_items_added']} Ã©lÃ©ments

---
*Rapport gÃ©nÃ©rÃ© automatiquement par le Daily Intelligence System v{self.version}*
"""
        
        return report

    def get_intelligence_metrics(self) -> Dict[str, Any]:
        """Retourne les mÃ©triques du systÃ¨me de veille"""
        if not self.intelligence_reports:
            return {"status": "no_data", "cycles_executed": 0}
        
        latest_cycle = self.intelligence_reports[-1]
        
        return {
            "system_name": self.name,
            "version": self.version,
            "cycles_executed": len(self.intelligence_reports),
            "agents_monitored": len(self.expert_agents),
            "latest_cycle": latest_cycle["summary"],
            "knowledge_enrichment_trend": self._calculate_enrichment_trend(),
            "intelligence_quality_trend": self._calculate_quality_trend()
        }

    def _calculate_enrichment_trend(self) -> Dict[str, float]:
        """Calcule la tendance d'enrichissement des connaissances"""
        if len(self.intelligence_reports) < 2:
            return {"trend": 0.0, "acceleration": False}
        
        recent_enrichments = [
            cycle["summary"]["knowledge_items_added"] 
            for cycle in self.intelligence_reports[-5:]
        ]
        
        avg_recent = sum(recent_enrichments) / len(recent_enrichments)
        
        older_enrichments = [
            cycle["summary"]["knowledge_items_added"] 
            for cycle in self.intelligence_reports[-10:-5]
        ]
        
        if older_enrichments:
            avg_older = sum(older_enrichments) / len(older_enrichments)
            trend = (avg_recent - avg_older) / avg_older if avg_older > 0 else 0
        else:
            trend = 0.0
        
        return {
            "trend": trend,
            "acceleration": trend > 0.1,
            "avg_daily_enrichment": avg_recent
        }

    def _calculate_quality_trend(self) -> Dict[str, float]:
        """Calcule la tendance de qualitÃ© de l'intelligence"""
        if len(self.intelligence_reports) < 2:
            return {"trend": 0.0, "improvement": False}
        
        recent_scores = [
            cycle["summary"]["intelligence_score"] 
            for cycle in self.intelligence_reports[-5:]
        ]
        
        avg_recent = sum(recent_scores) / len(recent_scores)
        
        return {
            "current_quality": avg_recent,
            "improvement": avg_recent > 0.8,
            "excellence_threshold": avg_recent > 0.9
        }

# Test du systÃ¨me de veille quotidienne
if __name__ == "__main__":
    intelligence_system = DailyIntelligenceSystem()
    
    print("=== TEST SYSTÃˆME DE VEILLE QUOTIDIENNE ===")
    
    # ExÃ©cution d'un cycle de veille
    cycle_result = intelligence_system.execute_daily_intelligence_cycle()
    
    print(f"\nðŸ“Š RÃ©sultats du cycle:")
    print(f"- Agents: {cycle_result['summary']['total_agents']}")
    print(f"- Rapports: {cycle_result['summary']['reports_generated']}")
    print(f"- Enrichissements: {cycle_result['summary']['knowledge_items_added']}")
    print(f"- Score: {cycle_result['summary']['intelligence_score']:.2f}")
    
    # GÃ©nÃ©ration du rapport quotidien
    print(f"\nðŸ“‹ Rapport quotidien:")
    daily_report = intelligence_system.generate_daily_intelligence_report()
    print(daily_report[:1000] + "..." if len(daily_report) > 1000 else daily_report)
    
    print(f"\nðŸ“ˆ MÃ©triques systÃ¨me:")
    metrics = intelligence_system.get_intelligence_metrics()
    print(json.dumps(metrics, indent=2, default=str))

